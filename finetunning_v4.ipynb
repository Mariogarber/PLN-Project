{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafded3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: torch in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 3)) (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 4)) (4.57.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 5)) (4.3.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 6)) (22.0.0)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 7)) (2.5.1)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 9)) (3.9.2)\n",
      "Requirement already satisfied: bert-score in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 10)) (0.3.13)\n",
      "Requirement already satisfied: seaborn in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 12)) (3.10.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 13)) (0.2.1)\n",
      "Requirement already satisfied: peft in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 14)) (0.18.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 15)) (1.12.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 16)) (0.48.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 17)) (5.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 18)) (1.7.2)\n",
      "Requirement already satisfied: protobuf==3.20.* in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 19)) (3.20.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 20)) (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from -r requirements.txt (line 21)) (2.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (80.9.0)\n",
      "Collecting sympy==1.13.1 (from torch->-r requirements.txt (line 3))\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (2025.10.23)\n",
      "Requirement already satisfied: requests in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from datasets->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from datasets->-r requirements.txt (line 5)) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from datasets->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from datasets->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 5)) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 5)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 5)) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 5)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets->-r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from rouge_score->-r requirements.txt (line 8)) (2.3.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from rouge_score->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from nltk->-r requirements.txt (line 9)) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from nltk->-r requirements.txt (line 9)) (1.5.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from matplotlib->-r requirements.txt (line 12)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from matplotlib->-r requirements.txt (line 12)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from matplotlib->-r requirements.txt (line 12)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from matplotlib->-r requirements.txt (line 12)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from matplotlib->-r requirements.txt (line 12)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from matplotlib->-r requirements.txt (line 12)) (3.2.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from peft->-r requirements.txt (line 14)) (7.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 17)) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 18)) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->-r requirements.txt (line 5)) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 4)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from anyio->httpx<1.0.0->datasets->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\mario\\anaconda3\\envs\\nlp2\\lib\\site-packages (from portalocker->sacrebleu->-r requirements.txt (line 7)) (311)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "Successfully installed sympy-1.13.1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5afbbed",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from finetunning_v2.data_manager import DataManager\n",
    "from finetunning_v2.tokenizer import DataTokenizer\n",
    "from finetunning_v2.mt5_lora import build_mt5_lora\n",
    "from finetunning_v2.data_collator import DataCollatorT5\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "from finetunning_v2.callbacks import (\n",
    "    PrintExamplesCallback,\n",
    "    PerplexityCallback,\n",
    "    MemoryCallback,\n",
    "    GradNormCallback,\n",
    "    LearningRateCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7518de",
   "metadata": {},
   "source": [
    "# 1. Entrenamiento con Train Entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee107b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:14:57] [INFO] Inicializando DataManager para idiomas: ['en', 'am', 'ar', 'de', 'es', 'hi', 'ru', 'uk', 'zh']\n",
      "loading file spiece.model from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\config.json\n",
      "Model config MT5Config {\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\config.json\n",
      "Model config MT5Config {\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "c:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "[11:15:01] [INFO] Tokenizer cargado: google/mt5-base\n",
      "[11:15:03] [INFO] Cargado 400 ejemplos para en\n",
      "[11:15:03] [INFO] Cargado 400 ejemplos para am\n",
      "[11:15:04] [INFO] Cargado 400 ejemplos para ar\n",
      "[11:15:04] [INFO] Cargado 400 ejemplos para de\n",
      "[11:15:05] [INFO] Cargado 400 ejemplos para es\n",
      "[11:15:05] [INFO] Cargado 400 ejemplos para hi\n",
      "[11:15:06] [INFO] Cargado 400 ejemplos para ru\n",
      "[11:15:06] [INFO] Cargado 400 ejemplos para uk\n",
      "[11:15:07] [INFO] Cargado 400 ejemplos para zh\n",
      "[11:15:07] [INFO] Dataset total cargado: 3600 muestras\n",
      "[11:15:07] [INFO] Cálculo de overlap (equal_percentage) completado.\n",
      "[11:15:07] [INFO] Stratified splits created:\n",
      "  train: 2880\n",
      "  val:   360\n",
      "  test:  360\n",
      "[11:15:07] [INFO] Curriculum datasets created:\n",
      "  easy:   1661 samples\n",
      "  medium: 708 samples\n",
      "  hard:   511 samples\n",
      "  full:   2880 samples\n",
      "loading file spiece.model from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\config.json\n",
      "Model config MT5Config {\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\config.json\n",
      "Model config MT5Config {\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "c:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "[11:15:11] [INFO] Loaded tokenizer google/mt5-base\n",
      "[11:15:11] [INFO] Tokenizing train/val/test splits...\n",
      "[11:15:11] [INFO]  → Tokenizing split `train` (2880 samples)\n",
      "[11:15:11] [INFO] Tokenizing dataset with 2880 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30dc63abd0fe4612ab46f81afce60bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset (num_proc=4):   0%|          | 0/2880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:15:50] [INFO]  → Tokenizing split `val` (360 samples)\n",
      "[11:15:50] [INFO] Tokenizing dataset with 360 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29122f9050e343e580ebc2a2f2379bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset (num_proc=4):   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:16:05] [INFO]  → Tokenizing split `test` (360 samples)\n",
      "[11:16:05] [INFO] Tokenizing dataset with 360 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d299a48593b4628bb023711130b5b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset (num_proc=4):   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\config.json\n",
      "Model config MT5Config {\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Attempting to create safetensors variant\n",
      "Attempting to convert .bin model on the fly to safetensors.\n",
      "loading configuration file generation_config.json from cache at C:\\Users\\mario\\.cache\\huggingface\\hub\\models--google--mt5-base\\snapshots\\2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Could not locate the custom_generate/generate.py inside google/mt5-base.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m collator = DataCollatorT5(tokenizer=dtok.tokenizer)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 4. Model + LoRA\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m model = \u001b[43mbuild_mt5_lora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle/mt5-base\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 5. TrainingArguments (los que definimos antes)\u001b[39;00m\n\u001b[32m     27\u001b[39m training_args = Seq2SeqTrainingArguments(\n\u001b[32m     28\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./mt5_detox_baseline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m     overwrite_output_dir=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     metric_for_best_model=\u001b[33m\"\u001b[39m\u001b[33meval_loss\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\OneDrive\\Documentos\\UPM\\Master_Data\\NLP\\PLN-Project\\finetunning_v2\\mt5_lora.py:54\u001b[39m, in \u001b[36mbuild_mt5_lora\u001b[39m\u001b[34m(base_model_name, r, lora_alpha, lora_dropout, target_modules, device)\u001b[39m\n\u001b[32m     44\u001b[39m lora_config = LoraConfig(\n\u001b[32m     45\u001b[39m     r=r,\n\u001b[32m     46\u001b[39m     lora_alpha=lora_alpha,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     target_modules=target_modules,\n\u001b[32m     51\u001b[39m )\n\u001b[32m     53\u001b[39m model = get_peft_model(model, lora_config)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Optional: print trainable params\u001b[39;00m\n\u001b[32m     57\u001b[39m trainable, total = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1371\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:957\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1357\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1352\u001b[39m             device,\n\u001b[32m   1353\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1354\u001b[39m             non_blocking,\n\u001b[32m   1355\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1356\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "dm = DataManager(languages=['en', 'am', 'ar', 'de', 'es', 'hi', 'ru', 'uk', 'zh'])\n",
    "dm.load_main_dataset()\n",
    "dm.compute_overlap_feature()\n",
    "dm.stratified_split(stratify_by=[\"language\"])  # como acordamos\n",
    "dm.create_curriculum_datasets()  # easy/medium/hard/full a nivel texto\n",
    "\n",
    "# 2. Tokenizer\n",
    "dtok = DataTokenizer(\n",
    "    tokenizer_name=\"google/mt5-base\",\n",
    "    prefix=\"detoxify_keep_meaning: \",\n",
    "    max_input_length=128,\n",
    "    max_target_length=128,\n",
    "    logger=dm.logger\n",
    ")\n",
    "\n",
    "tokenized_splits = dtok.tokenize_splits(dm.splits)\n",
    "train_dataset = tokenized_splits[\"train\"]\n",
    "eval_dataset = tokenized_splits[\"val\"]\n",
    "\n",
    "# 3. Collator\n",
    "collator = DataCollatorT5(tokenizer=dtok.tokenizer)\n",
    "\n",
    "# 4. Model + LoRA\n",
    "model = build_mt5_lora(base_model_name=\"google/mt5-base\", device=\"cuda\")\n",
    "\n",
    "# 5. TrainingArguments (los que definimos antes)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5_detox_baseline\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    log_level=\"info\",\n",
    "    save_total_limit=4,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    fp16=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "# 6. Trainer (aquí enchufarías también los callbacks que definimos)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=dtok.tokenizer,\n",
    "    data_collator=collator,\n",
    "    callbacks=[\n",
    "        PrintExamplesCallback(dtok.tokenizer, every_steps=50),\n",
    "        PerplexityCallback(),\n",
    "        MemoryCallback(),\n",
    "        GradNormCallback(every_steps=50),\n",
    "        LearningRateCallback(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2960a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2,880\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 3,600\n",
      "  Number of trainable parameters = 1,769,472\n",
      "c:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  10/3600 01:29 < 11:11:06, 0.09 it/s, Epoch 0.03/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\trainer.py:4110\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4108\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   4109\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m4110\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4111\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   4112\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   4113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\peft\\peft_model.py:2259\u001b[39m, in \u001b[36mPeftModelForSeq2SeqLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, inputs_embeds, decoder_input_ids, decoder_attention_mask, decoder_inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[39m\n\u001b[32m   2257\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(**kwargs):\n\u001b[32m   2258\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m2259\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2260\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2261\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2262\u001b[39m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2265\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2266\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2267\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2268\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2269\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2270\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2271\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2273\u001b[39m batch_size = _get_batch_size(input_ids, inputs_embeds)\n\u001b[32m   2274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decoder_attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2275\u001b[39m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:308\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\models\\mt5\\modeling_mt5.py:1787\u001b[39m, in \u001b[36mMT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1784\u001b[39m         decoder_attention_mask = decoder_attention_mask.to(\u001b[38;5;28mself\u001b[39m.decoder.first_device)\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1797\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1798\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1803\u001b[39m sequence_output = decoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1805\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\models\\mt5\\modeling_mt5.py:1087\u001b[39m, in \u001b[36mMT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m   1085\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m-> \u001b[39m\u001b[32m1087\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1103\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1105\u001b[39m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[32m   1106\u001b[39m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[32m   1107\u001b[39m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\models\\mt5\\modeling_mt5.py:589\u001b[39m, in \u001b[36mMT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    587\u001b[39m do_cross_attention = \u001b[38;5;28mself\u001b[39m.is_decoder \u001b[38;5;129;01mand\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_cross_attention:\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     cross_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m     hidden_states = cross_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    602\u001b[39m     \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\models\\mt5\\modeling_mt5.py:517\u001b[39m, in \u001b[36mMT5LayerCrossAttention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_values, use_cache, query_length, output_attentions, cache_position)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    504\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    515\u001b[39m ):\n\u001b[32m    516\u001b[39m     normed_hidden_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mEncDecAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m     layer_output = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(attention_output[\u001b[32m0\u001b[39m])\n\u001b[32m    530\u001b[39m     outputs = (layer_output,) + attention_output[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\transformers\\models\\mt5\\modeling_mt5.py:367\u001b[39m, in \u001b[36mMT5Attention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_values, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# if key_value_states are provided this layer is used as a cross-attention layer for the decoder\u001b[39;00m\n\u001b[32m    365\u001b[39m is_cross_attention = key_value_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m query_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m query_states = query_states.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.n_heads, \u001b[38;5;28mself\u001b[39m.key_value_proj_dim).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# Check is encoder-decoder model is being used. Otherwise we'll get `DynamicCache`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:807\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m x = \u001b[38;5;28mself\u001b[39m._cast_input_dtype(x, lora_A.weight.dtype)\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m active_adapter \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lora_variant:  \u001b[38;5;66;03m# vanilla LoRA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     result = result + lora_B(lora_A(\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)) * scaling\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    809\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.lora_variant[active_adapter].forward(\n\u001b[32m    810\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    811\u001b[39m         active_adapter=active_adapter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    815\u001b[39m         **kwargs,\n\u001b[32m    816\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mario\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\torch\\nn\\functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8729133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "toxic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold_neutral",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_neutral",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "54581225-49f3-4d02-8a66-6bd77e2852ea",
       "rows": [
        [
         "0",
         "detoxify_keep_meaning: wir brauchen das scheiß #Europa nicht ich bin #Deutscher und kein Europäer #btw2017",
         "wir brauchen das #Europa nicht ich bin #Deutscher und kein Europäer #btw2017",
         "Wir brauchen das scheiß #Europa nicht ich bin #Deutscher und kein Europäer #btw2017"
        ],
        [
         "1",
         "detoxify_keep_meaning: I HATE YOU for deliting pages stay away from my pages",
         "I dislike you for deleting my pages. Stay away from my pages.",
         "I HATE YOU for deliting pages stay away from my pages"
        ],
        [
         "2",
         "detoxify_keep_meaning: До деяких людей не виникає інших питань, окрім \"Ти блять уже родився таким мудаком?\".",
         "До деяких людей не виникає інших питань, окрім \"Ти уже родився таким?\".",
         "До деяких людей не виникає інших питань, окрім \"Ти блять уже родився таким мудаком?\"."
        ],
        [
         "3",
         "detoxify_keep_meaning: तू कहा अपना झोपड़ा मरवा रही है मादरचोद कूत्ती ?",
         "तू अब कहां अपनी इज्जत से खिलवाड़ करवा रही है ?",
         "तू कहा अपना झोपड़ा मरवा रही है मादरचोद कूत्ती ?"
        ],
        [
         "4",
         "detoxify_keep_meaning: ты сама то что сделала? ни хера ты не сделала",
         "Ты сама то что сделала? Ничего ты не сделала",
         "Ты сама то что сделала? ни хера ты не сделала"
        ],
        [
         "5",
         "detoxify_keep_meaning: 民主党搞的和平演变路线,说白了就是葵花宝典。现在美国国内也是一堆女权主义、黑命贵的政治正确。把自己切了让别人死。典型的又蠢又坏。但是你不防还真不行。不防真容易死。",
         "民主党搞的和平演变路线,说白了就是葵花宝典。现在美国国内也是一堆女权主义、重视黑人生命的政治正确。把自己切了让别人死。典型的又不明智又坏。但是你不防还真不行。不防真容易死。",
         "民主党搞的和平演变路线,说白了就是葵花宝典。现在美国国内也是一堆女权主义、黑命贵的政治正确。把自己切了让别人死。典型的又蠢又坏。但是你不防还真不行。不防真容易死。"
        ],
        [
         "6",
         "detoxify_keep_meaning: та тоді якийсь пиздец бувв мене рідко губи тріскають",
         "Та тоді якийсь ужас бувв мене рідко губи тріскають",
         "та тоді якийсь пиздец бувв мене рідко губи тріскають"
        ],
        [
         "7",
         "detoxify_keep_meaning: #الهلال حارس قزم ولاعب وسط قلب دفاع أما أن لهذا العبث ان يتوقف مايحدث في الهلال يتطلب تدخل اعضاء الشرف لإنقاذ ا...",
         "#الهلال حارس هاوي ولاعب وسط قلب دفاع أما أن لهذا العبث ان يتوقف مايحدث في الهلال يتطلب تدخل اعضاء الشرف لإنقاذ ا...",
         "#الهلال حارس قزم ولاعب وسط قلب دفاع أما أن لهذا العبث ان يتوقف مايحدث في الهلال يتطلب تدخل اعضاء الشرف لإنقاذ ا..."
        ],
        [
         "8",
         "detoxify_keep_meaning: Vaya, nunca pensé oir decir eso a una mujer",
         "Nunca esperé escuchar eso de una mujer.",
         "Vaya, nunca pensé oir decir eso a una mujer"
        ],
        [
         "9",
         "detoxify_keep_meaning: አንተም ክፉ ነበርክ ክፉ አዘዘብህ አንደ ገና ዳቦ እሳት ነደደብህ። የምንልበት ቀን ሩቅ ሰይደለም????",
         "በክፋቱ የሚታወቅ የስራውን ሊያገኝ ነው የምንልበት ቀን ሩቅ አይደለም ??",
         "አንተም ክፉ ነበርክ ክፉ አዘዘብህ አንደ ገና ዳቦ እሳት ነደደብህ። የምንልበት ቀን ሩቅ ሰይደለም????"
        ],
        [
         "10",
         "detoxify_keep_meaning: إنه أسوأ عمدة حظينا به على الإطلاق!",
         "إنه العمدة غير المناسب على الإطلاق!",
         "إنه أسوأ عمدة حظينا به على الإطلاق!"
        ],
        [
         "11",
         "detoxify_keep_meaning: а это стадо олигархов в думе знают что в стране есть детские дома и дома престарелых?! или уже все уничтожили?!....",
         "эти олигархи в думе знают что в стране есть детские дома и дома престарелых?! или уже все уничтожили?!....",
         "а это стадо олигархов в думе знают что в стране есть детские дома и дома престарелых?! или уже все уничтожили?!...."
        ],
        [
         "12",
         "detoxify_keep_meaning: سبحان الله كأنك تتكلم عن نفسك فيه احد ما أحتل مصر يابهيمه وشارع الهرم يشه...",
         "سبحان الله كأنك تتكلم عن نفسك فيه احد ما أحتل مصر وشارع الهرم يشه...",
         "سبحان الله كأنك تتكلم عن نفسك فيه احد ما أحتل مصر يابهيمه وشارع الهرم يشه..."
        ],
        [
         "13",
         "detoxify_keep_meaning: يعني حياة المواطنين رخيصه عنكم .. ما يهمك من مات ع قد ما يهمك تثبت انك صح .. لعنة الله عليكم ولعنة الله ع السياسه والسياسيين",
         "يعني حياة المواطنين رخيصه عنكم .. ما يهمك من مات ع قد ما يهمك تثبت انك صح .. مافي خير في السياسه والسياسيين",
         "يعني حياة المواطنين رخيصه عنكم .. ما يهمك من مات ع قد ما يهمك تثبت انك صح .. لعنة الله عليكم ولعنة الله ع السياسه والسياسيين"
        ],
        [
         "14",
         "detoxify_keep_meaning: мразь тебя нужно вывести за грань , захрибетник- жреш с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "тебя нужно вывести за грань , ешь с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "Человек тебя нужно вывести за грань , захрибетник- жреш с рук этих учителей и рабочего класса и их -же угнетаешь."
        ],
        [
         "15",
         "detoxify_keep_meaning: Da diese Meldung von den Vasallen Merkels kommt, würde ich sagen das diese Meldung der Tagesschau gelogen ist!! Lügenpresse und Lügen Medien",
         "Da diese Meldung von den Unterstützern Merkels kommt, würde ich sagen das diese Meldung der Tagesschau gelogen ist!! Unehrliche Presse und lügende Medien",
         "Da diese Meldung von den Vasallen Merkels kommt, würde ich sagen das diese Meldung der Tagesschau gelogen ist!! Lügenpresse und Lügen Medien"
        ],
        [
         "16",
         "detoxify_keep_meaning: piss me off , fuckin jerk , get on my nerves .",
         "get on my nerves",
         "Pis me off , fuckin jerk , get on my nerves ."
        ],
        [
         "17",
         "detoxify_keep_meaning: No pasa nada, él es el mas preparado y el mas valiente que ya lo decia la abuela Carmena.",
         "No hay problema, él es el más preparado y valiente, como lo afirmaba la abuela Carmena.",
         "No pasa nada, él es el mas preparado y el mas valiente que ya lo decia la abuela Carmena."
        ],
        [
         "18",
         "detoxify_keep_meaning: 跑到反同群里面开盒,真的是狗啊",
         "跑到对反对性少数群体的群里面开盒,真的不太好啊",
         "跑到反同群里面开盒,真的是狗啊"
        ],
        [
         "19",
         "detoxify_keep_meaning: Israelitas, chinos, moros, culés... así estaba el Bernabéu ese día, que daba entre pena y asco.",
         "Israelitas, chinos, moros,... así estaba el Bernabéu ese día, que daba entre pena y asco.",
         "Israelitas, chinos, moros, culés... así estaba el Bernabéu ese día, que daba entre pena y asco."
        ],
        [
         "20",
         "detoxify_keep_meaning: а тебя это с какой стороны колышет, уёбище?",
         "А вас это очень волнует?",
         "а тебя это с какой стороны колышет, уёбище?"
        ],
        [
         "21",
         "detoxify_keep_meaning: اجل النجار يسجل علينا الله يلعن امك فريق",
         "اجل النجار يسجل عليناق",
         "اجل النجار يسجل علينا الله يلعن امك فريق"
        ],
        [
         "22",
         "detoxify_keep_meaning: कोठे की पैदाइस साला दल्ला भड़वा आजम",
         "अच्छा आदमी नहीं है आजम",
         "कोठे की पैदाइस साला दल्ला भड़वा आजम"
        ],
        [
         "23",
         "detoxify_keep_meaning: هذا الرجل غبي جداً.",
         "هذا الرجل غير مدروس جداً.",
         "هذا الرجل غبي جداً."
        ],
        [
         "24",
         "detoxify_keep_meaning: ቀድሞ ነበር እንጂ መጥኖ መደቆስ አሁን ምን ያደርጋል ድስት ጥዶ ማልቀስ። ጉራ ብቻ ለዚሁ ነበር ያ ሁላ ፉከራ ???",
         "ቀድሞ ነበር እንጂ መጥኖ መደቆስ አሁን ምን ያደርጋል ድስት ጥዶ ማልቀስ። ወሬ ብቻ ምንም አያሰራም፡ ተግበር",
         "ቀድሞ ነበር እንጂ መጥኖ መደቆስ አሁን ምን ያደርጋል ድስት ጥዶ ማልቀስ። ጉራ ብቻ ለዚሁ ነበር ያ ሁላ ፉከራ ???"
        ],
        [
         "25",
         "detoxify_keep_meaning: вже майже четверта, а я не сплю, блять",
         "вже майже четверта, а я не сплю, що за",
         "Вже майже четверта, а я не сплю"
        ],
        [
         "26",
         "detoxify_keep_meaning: مائة ألف شخص دفعوا المال لمشاهدة هذه القمامة.",
         "مائة ألف شخص دفعوا المال لمشاهدة هذا المحتوى",
         "مائة ألف شخص دفعوا المال لمشاهدة هذه القمامة."
        ],
        [
         "27",
         "detoxify_keep_meaning: En catalán se escribe Espanya. Para dárselas usted de ser periodista, no tieene usted puta idea de escribir.",
         "En catalán se escribe Espanya. Para dárselas usted de ser periodista, no tieene usted idea de escribir.",
         "En catalán se escribe Espanya. Para dárselas usted de ser periodista, no tieene usted puta idea de escribir."
        ],
        [
         "28",
         "detoxify_keep_meaning: ደንቆሮ በክት የበከትህ ገረድ የስሙኒ ልጅ አንተ ከማንም ጋ ልትከራከር አትችልም ሆድ እስካፉ በክት ስለሆንህ",
         "አንተ ከማንም ጋ ልትከራከር አትችልም ራስ ወዳድ ስለሆንክ",
         "ደንቆሮ በክት የበከትህ ገረድ የስሙኒ ልጅ አንተ ከማንም ጋ ልትከራከር አትችልም ሆድ እስካፉ በክት ስለሆንህ"
        ],
        [
         "29",
         "detoxify_keep_meaning: ну і хуй з ним.",
         "Ну і фіг з ним",
         "ну і хуй з ним."
        ],
        [
         "30",
         "detoxify_keep_meaning: يختار الثاني عشان ما محد يقول عنه قزم",
         "يختار الثاني عشان ما محد يقول عنه قصير",
         "يختار الثاني عشان ما محد يقول عنه قزم"
        ],
        [
         "31",
         "detoxify_keep_meaning: 女拳***",
         "极端女权主义者***",
         "女拳***"
        ],
        [
         "32",
         "detoxify_keep_meaning: No hay que indicar niña \"blanca española\" ni nada?",
         "No es necesario especificar la nacionalidad o etnia al referirse a una niña.",
         "No hay que indicar niña \"blanca española\" ni nada?"
        ],
        [
         "33",
         "detoxify_keep_meaning: वाह भेनचोद वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग लगे हुए हैं ...",
         "वाह भाई वाह ... एक आदमी को नीचा गिराने के लिए कितने लोग हैं",
         "वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग लगे हुए हैं ..."
        ],
        [
         "34",
         "detoxify_keep_meaning: 但事实上,大部分都是找个接盘的,这也就罢了,到最后接盘住了,他们还不安生,各种乱搞,这才是最让人觉得恶心的",
         "但事实上,大部分都是找个接盘的,这也就罢了,到最后接盘住了,他们还不安生,各种行为不检点,这才是最让人觉得不舒服的",
         "但事实上,大部分都是找个接盘的,这也就罢了,到最后接盘住了,他们还不安生,各种乱搞,这才是最让人觉得恶心的"
        ],
        [
         "35",
         "detoxify_keep_meaning: кошмар, руки бы оторвать. придурки .:o",
         "ужасно!",
         "Комар, руки бы оторвать. придурки .:o"
        ],
        [
         "36",
         "detoxify_keep_meaning: तेरा लौंडा बहुत बैट लेकर घूमता और सरकारी अफसर को पीटता है ।",
         "तेरा लौंडा सरकारी अफसर के बारे में कुछ भी बोलता है |",
         "तेरा लौंडा बहुत बैट लेकर घूमता और सरकारी अफसर को पीटता है ।"
        ],
        [
         "37",
         "detoxify_keep_meaning: ጥሎብሽ እኔ መስማት ሴራ መስሎ ታይቶሽ ነበራ ????",
         "የእኔ መስማት ለነገር መስሎ ታይቶሽ ነበር መሰለኝ????",
         "ጥሎብሽ እኔ መስማት ሴራ መስሎ ታይቶሽ ነበራ ????"
        ],
        [
         "38",
         "detoxify_keep_meaning: collins , is an idiot , but we didnt need this article to establish that fact .",
         "Colin is not so intelligent but we didn't need this article to establish this fact.",
         ", is an idiot , but we didnt need this article to establish that fact ."
        ],
        [
         "39",
         "detoxify_keep_meaning: هذه ليست سياسة، هذه ليست سوى ثور مغرور للجماهير الجاهلة.",
         "هذه ليست سياسة",
         "هذه ليست سياسة، هذه ليست سوى ثور مغرور للجماهير الجاهلة."
        ],
        [
         "40",
         "detoxify_keep_meaning: انت احول فريقك داج ..بلاش مجامله وتطبيل على الحكم",
         "انت مش شايف فريقك داج ..بلاش مجامله وتطبيل على الحكم",
         "انت احول فريقك داج ..بلاش مجامله وتطبيل على الحكم"
        ],
        [
         "41",
         "detoxify_keep_meaning: भड़वे के पास कुत्ता जैसा नाक है हरामखोर पत्रकार",
         "उस चापलूस पत्रकार को तुरंत सब कुछ पता चल जाता है",
         "भड़वे के पास कुत्ता जैसा नाक है हरामखोर पत्रकार"
        ],
        [
         "42",
         "detoxify_keep_meaning: и наверное написав эдакую херню, ещё и гордый ходит , как бамбук.",
         "И наверное написав такую ерунду, ещё и гордый ходит",
         "И наверное написав эдакую херню, ещё и гордый ходит , как бамбук."
        ],
        [
         "43",
         "detoxify_keep_meaning: मादरचोद हम नेपाल चले जाएं ?",
         "हम नेपाल चले जाएं ?",
         "मादरचोद हम नेपाल चले जाएं ?"
        ],
        [
         "44",
         "detoxify_keep_meaning: Me cuesta creer que haya alguien igual de subnormal que Dalas.",
         "Me cuesta creer que haya alguien igual que Dalas.",
         "Me cuesta creer que haya alguien igual de subnormal que Dalas."
        ],
        [
         "45",
         "detoxify_keep_meaning: اشرف وانزه من ابوك يا ابن سته وستين زنوه",
         "اشرف وانزه من ابوك يا ابن سته وستين محترم",
         "اشرف وانزه من ابوك يا ابن سته وستين زنوه"
        ],
        [
         "46",
         "detoxify_keep_meaning: не хуй руку поднимать на благородное создание, а сам он животное.",
         "Не надо руку поднимать на благородное создание, а сам он нехороший человек",
         "Не хуй руку поднимать на благородное создание, а сам он животное."
        ],
        [
         "47",
         "detoxify_keep_meaning: Buah yo no me haría nunca un twitter, eso está lleno de rojos de mierda.",
         "Yo no me haría nunca un twitter, eso está lleno de rojos.",
         "Buah yo no me haría nunca un twitter, eso está lleno de rojos de mierda."
        ],
        [
         "48",
         "detoxify_keep_meaning: أنا متأكد من أن بعضهم متحيز سياسيًا، وبعضها يغطي مؤخرته ويتظاهر بأنه لا يوجد شيء خاطئ.",
         "أنا متأكد من أن بعضهم متحيز سياسيًا، ويتظاهر بأنه لا يوجد شيء خاطئ.",
         "أنا متأكد من أن بعضهم متحيز سياسيًا، وبعضها يغطي مؤخرته ويتظاهر بأنه لا يوجد شيء خاطئ."
        ],
        [
         "49",
         "detoxify_keep_meaning: твоё очко уходит в пользу форума!",
         "ваш балл уходит в пользу форума!",
         "Ты уходит в пользу форума!"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 360
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>gold_neutral</th>\n",
       "      <th>predicted_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>detoxify_keep_meaning: wir brauchen das scheiß...</td>\n",
       "      <td>wir brauchen das #Europa nicht ich bin #Deutsc...</td>\n",
       "      <td>Wir brauchen das scheiß #Europa nicht ich bin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detoxify_keep_meaning: I HATE YOU for deliting...</td>\n",
       "      <td>I dislike you for deleting my pages. Stay away...</td>\n",
       "      <td>I HATE YOU for deliting pages stay away from m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detoxify_keep_meaning: До деяких людей не вини...</td>\n",
       "      <td>До деяких людей не виникає інших питань, окрім...</td>\n",
       "      <td>До деяких людей не виникає інших питань, окрім...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detoxify_keep_meaning: तू कहा अपना झोपड़ा मरवा...</td>\n",
       "      <td>तू अब कहां अपनी इज्जत से खिलवाड़ करवा रही है ?</td>\n",
       "      <td>तू कहा अपना झोपड़ा मरवा रही है मादरचोद कूत्ती ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detoxify_keep_meaning: ты сама то что сделала?...</td>\n",
       "      <td>Ты сама то что сделала? Ничего ты не сделала</td>\n",
       "      <td>Ты сама то что сделала? ни хера ты не сделала</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>detoxify_keep_meaning: A su vez que no es lo m...</td>\n",
       "      <td>A su vez que no es lo mismo ser cristiano que ...</td>\n",
       "      <td>A su vez que no es lo mismo ser cristiano que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>detoxify_keep_meaning: 全部共同特点:太丑了</td>\n",
       "      <td>全部共同特点:太不符合我个人的审美了</td>\n",
       "      <td>全部共同特点:太丑了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>detoxify_keep_meaning: веселись сегодня ептить...</td>\n",
       "      <td>Веселись сегодня, удрученный ты наш)))</td>\n",
       "      <td>сегодня веселись сегодня ептить удручённый ты ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>detoxify_keep_meaning: لا لا لا الحكم ده غبي ا...</td>\n",
       "      <td>لا لا لا الحكم ده جاهل اوي كده ليه</td>\n",
       "      <td>لا لا لا الحكم ده غبي اوي كده ليه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>detoxify_keep_meaning: Bei #Halbneger meldet s...</td>\n",
       "      <td>Bei bestimmten Themen meldet sich Till #Schwei...</td>\n",
       "      <td>Bei #Halbneger meldet sich Till #Schweiger gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 toxic  \\\n",
       "0    detoxify_keep_meaning: wir brauchen das scheiß...   \n",
       "1    detoxify_keep_meaning: I HATE YOU for deliting...   \n",
       "2    detoxify_keep_meaning: До деяких людей не вини...   \n",
       "3    detoxify_keep_meaning: तू कहा अपना झोपड़ा मरवा...   \n",
       "4    detoxify_keep_meaning: ты сама то что сделала?...   \n",
       "..                                                 ...   \n",
       "355  detoxify_keep_meaning: A su vez que no es lo m...   \n",
       "356                  detoxify_keep_meaning: 全部共同特点:太丑了   \n",
       "357  detoxify_keep_meaning: веселись сегодня ептить...   \n",
       "358  detoxify_keep_meaning: لا لا لا الحكم ده غبي ا...   \n",
       "359  detoxify_keep_meaning: Bei #Halbneger meldet s...   \n",
       "\n",
       "                                          gold_neutral  \\\n",
       "0    wir brauchen das #Europa nicht ich bin #Deutsc...   \n",
       "1    I dislike you for deleting my pages. Stay away...   \n",
       "2    До деяких людей не виникає інших питань, окрім...   \n",
       "3       तू अब कहां अपनी इज्जत से खिलवाड़ करवा रही है ?   \n",
       "4         Ты сама то что сделала? Ничего ты не сделала   \n",
       "..                                                 ...   \n",
       "355  A su vez que no es lo mismo ser cristiano que ...   \n",
       "356                                 全部共同特点:太不符合我个人的审美了   \n",
       "357             Веселись сегодня, удрученный ты наш)))   \n",
       "358                 لا لا لا الحكم ده جاهل اوي كده ليه   \n",
       "359  Bei bestimmten Themen meldet sich Till #Schwei...   \n",
       "\n",
       "                                     predicted_neutral  \n",
       "0    Wir brauchen das scheiß #Europa nicht ich bin ...  \n",
       "1    I HATE YOU for deliting pages stay away from m...  \n",
       "2    До деяких людей не виникає інших питань, окрім...  \n",
       "3      तू कहा अपना झोपड़ा मरवा रही है मादरचोद कूत्ती ?  \n",
       "4        Ты сама то что сделала? ни хера ты не сделала  \n",
       "..                                                 ...  \n",
       "355  A su vez que no es lo mismo ser cristiano que ...  \n",
       "356                                         全部共同特点:太丑了  \n",
       "357  сегодня веселись сегодня ептить удручённый ты ...  \n",
       "358                  لا لا لا الحكم ده غبي اوي كده ليه  \n",
       "359  Bei #Halbneger meldet sich Till #Schweiger gro...  \n",
       "\n",
       "[360 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"modelos/finetune_v2_1/test_results_batch.csv\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1162ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "equals",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "79b40aae-921c-4538-836b-071095c285fd",
       "rows": [
        [
         "True",
         "288"
        ],
        [
         "False",
         "72"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "equals\n",
       "True     288\n",
       "False     72\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_modified = results.copy()\n",
    "\n",
    "results_modified['toxic'] = results_modified['toxic'].apply(lambda x: x.replace(\"detoxify_keep_meaning: \", \"\").strip())\n",
    "\n",
    "results_modified['equals'] = results_modified.apply(lambda row: row['toxic'].lower() == row['predicted_neutral'].lower(), axis=1)\n",
    "\n",
    "results_modified['equals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb00f471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "results_modified['equals'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.xticks(ticks=[0, 1], labels=['Equal', 'Not Equal'], rotation=0)\n",
    "plt.ylabel('Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da187c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "toxic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold_neutral",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_neutral",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "equals",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "80c33cda-4263-4969-b482-581475bdd6f5",
       "rows": [
        [
         "14",
         "мразь тебя нужно вывести за грань , захрибетник- жреш с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "тебя нужно вывести за грань , ешь с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "Человек тебя нужно вывести за грань , захрибетник- жреш с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "False"
        ],
        [
         "16",
         "piss me off , fuckin jerk , get on my nerves .",
         "get on my nerves",
         "Pis me off , fuckin jerk , get on my nerves .",
         "False"
        ],
        [
         "25",
         "вже майже четверта, а я не сплю, блять",
         "вже майже четверта, а я не сплю, що за",
         "Вже майже четверта, а я не сплю",
         "False"
        ],
        [
         "33",
         "वाह भेनचोद वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग लगे हुए हैं ...",
         "वाह भाई वाह ... एक आदमी को नीचा गिराने के लिए कितने लोग हैं",
         "वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग लगे हुए हैं ...",
         "False"
        ],
        [
         "35",
         "кошмар, руки бы оторвать. придурки .:o",
         "ужасно!",
         "Комар, руки бы оторвать. придурки .:o",
         "False"
        ],
        [
         "38",
         "collins , is an idiot , but we didnt need this article to establish that fact .",
         "Colin is not so intelligent but we didn't need this article to establish this fact.",
         ", is an idiot , but we didnt need this article to establish that fact .",
         "False"
        ],
        [
         "49",
         "твоё очко уходит в пользу форума!",
         "ваш балл уходит в пользу форума!",
         "Ты уходит в пользу форума!",
         "False"
        ],
        [
         "60",
         "дак и нечего с своим свиным рылом лезть ко всем .....",
         "дак и нечего лезть ко всем .....",
         "дак и нечего с своим рылом лезть ко всем .....",
         "False"
        ],
        [
         "63",
         "Ja schnell alle Bäume weg, 5G Handys kaufen und Bürgermeister den Sack lutschen du kleine Profesora",
         "Ja schnell alle Bäume weg, 5G Handys kaufen und Bürgermeister schmeicheln Profesora",
         "Ja schnell alle Bäume weg, 5G Handys kaufen und Bürgermeister den Sack lutschen",
         "False"
        ],
        [
         "65",
         "везде бабушки блядь а дедушки ведь она пиздует к внукам а дед ебашет на работе и всегда она хорошая а дед хуевый парадокс",
         "везде бабушки и дедушки: бабушка ездит к внукам, а дед работает, но она всегда хорошая, а дедушка плохой. Парадокс!",
         "Везде бабушки блядь а дедушки ведь она пиздует к внукам а дед ебашет на работе и всегда она хорошая",
         "False"
        ],
        [
         "66",
         "Тому доводиться вмикати режим хитрожопість.",
         "Тому доводиться вмикати режим хитрощів.",
         "Тому доводиться вмикати режим хитрожопості.",
         "False"
        ],
        [
         "67",
         "这就是慕勾正常人谁和蝻结婚啊",
         "这就是让我反感的女性正常人谁和国内男性结婚啊",
         "这就是慕勾正常人谁和黑人结婚啊",
         "False"
        ],
        [
         "68",
         "явная цензура, 100% заказ пидаров с газпрома, ебучая контора",
         "явная цензура, 100% заказ людей с газпрома, плохая контора",
         "Яная цензура, 100% заказ пидаров с газпрома, ебучая контора",
         "False"
        ],
        [
         "69",
         "тобто блядь? тобі більше 25?!",
         "тобто? тобі більше 25?!",
         "Точно блядь? тобі більше 25?!",
         "False"
        ],
        [
         "72",
         "Son los mejores. Paguita, alquiler y seguridad social ya. Rasistas",
         "Son los mejores. Paguita, alquiler y seguridad social ya.",
         "Los mejores. Paguita, alquiler y seguridad social ya.",
         "False"
        ],
        [
         "74",
         "курва галичанская , приехала в одессу со своим уставом !",
         "глупышка, приехала в одессу со своим уставом !",
         ", приехала в одессу со своим уставом !",
         "False"
        ],
        [
         "75",
         "عنجد هيدا شارون هيدا جماعة شارون لعنة الله عليك يا مجرم يا ابن الحرام لعنة الله يارب تخسر أولادك",
         "عنجد هيدا شارون هيدا جماعة شارون يارب تخسر أولادك",
         "عنجد هيدا شارون لعنة الله عليك يا مجرم يا ابن الحرام لعنة الله يارب تخسر أولادك",
         "False"
        ],
        [
         "77",
         "а свое мнение и мысли при себе держи мудило ебаное.",
         "оставьте свои мысли при себе",
         "а свое мнение и мысли при себе держи ебаное.",
         "False"
        ],
        [
         "87",
         "op沙軟罢了",
         "op不明智罢了",
         "Op沙软罢了",
         "False"
        ],
        [
         "89",
         "Merkel: \"Die Bürger haben keine Lust auf Zuständigkeitsdebatten\" ??? Eben ein verlogenes Miststück mit ausreichender Denunziantenerfahrung😜",
         "Merkel: \"Die Bürger haben keine Lust auf Zuständigkeitsdebatten\" ??? Eben eine Politikerin mit ausreichender rethorischer Erfahrung 😜",
         "Angela: \"Die Bürger haben keine Lust auf Zuständigkeitsdebatten\" ??? Eben ein verlogenes Miststück mit ausreichender Denunziantenerfahrung😜",
         "False"
        ],
        [
         "91",
         "وأمور أخرى غبية .",
         "وأمور أخرى سيئة .",
         "أمور أخرى غبية .",
         "False"
        ],
        [
         "98",
         "Dummes Gelaber wegen Abschiebung in unsichere Staaten. Berlin, Manchester. und Nizza liegen auch in unsicheren Staaten. Also keine Hemmungen.",
         "Unnötiges Gespräch wegen Abschiebung in unsichere Staaten. Berlin, Manchester. und Nizza liegen auch in unsicheren Staaten. Also keine Hemmungen.",
         "wegen Abschiebung in unsichere Staaten. Berlin, Manchester. und Nizza liegen auch in unsicheren Staaten. Also keine Hemmungen.",
         "False"
        ],
        [
         "104",
         "सूअर लोग अपना अस्तित्व बचाने में लगे हैं।।",
         "बुरे लोग अपने अस्तित्व को बचाने में लगे हैं |",
         "अपना अस्तित्व बचाने में लगे हैं।।",
         "False"
        ],
        [
         "112",
         "Aquí va una canción para todos y cada uno de los putos fascistas del PP... Fuck You de Lily Allen",
         "Aquí tenéis una canción para todos y cada uno de los PP... You de Lily Allen",
         "Aquí va una canción para todos y cada uno de los fascistas del PP... Fuck You de Lily Allen",
         "False"
        ],
        [
         "113",
         "if you think a town in texas would cover this kind of shit up you re insane .",
         "If you think a town in Texas would cover these things your wrong.",
         "If you think a town in texas would cover this kind of shit up you re insane",
         "False"
        ],
        [
         "132",
         "так этот акимат только себе в карман ложит бабки а для людей они нечего делать не будут хуилы ни дорог ни парка полная жопа гавноеды",
         "так этот акимат только себе в карман кладет деньги. а для людей они нечего делать не будут. ни дорог, ни парка. полное разочарование",
         "так этот акимат только себе в карман ложит бабки а для людей они нечего делать не будут",
         "False"
        ],
        [
         "143",
         "it s like fucking jurassic park , but much fluffier ! .",
         "it s like jurassic park , but much fluffier !",
         "It s like fucking jurassic park , but much fluffier !",
         "False"
        ],
        [
         "148",
         "सालो को जेल में डाल तो क्या रे बिकाऊ दलाल पत्रकार",
         "ऐसे बिकाऊ चापलूस पत्रकार को जेल में डाल दो",
         "सालो को जेल में डाल तो क्या रे बिकाऊ पत्रकार",
         "False"
        ],
        [
         "149",
         "केला कहाँ मिल रहा है आज कल सुअर ?",
         "केला कहाँ मिल रहा है आज कल ?",
         "कहाँ मिल रहा है आज कल सुअर ?",
         "False"
        ],
        [
         "151",
         "so shut the hell up until you know what it is your talking about .",
         "So keep quiet untill you know what you are talking about.",
         "So shut the hell up until you know what it is your talking about",
         "False"
        ],
        [
         "165",
         "La mitad catalana borrega independentista sigue creyéndose sus mentiras.",
         "La mitad catalana independentista sigue creyéndose sus mentiras",
         "La mitad catalana sigue creyéndose sus mentiras.",
         "False"
        ],
        [
         "167",
         "舔狗龜男比拳師更可恨",
         "单方面付出的卑微男性比极端的性别平等倡导者更可恨",
         "舔狗男比拳師更可恨",
         "False"
        ],
        [
         "168",
         "Who is this? አንተ ደግሞ የማነህ ዘረጦ ፈሳም? ፈታኝ ወቅትስ የትኛው ነው? አማራውና መከላከያው ውጊያ ሜዳ ላይ ሲውል ይህ ሚድያ የት",
         "አንተ ምን እያልክ ነው ? ፈታኝ ወቅትስ የትኛው ነው? አማራውና መከላከያው ውጊያ ሜዳ ላይ ሲውል ይህ ሚድያ የት",
         "አንተ ደግሞ የማነህ ዘረጦ ፈሳም? ፈታኝ ወቅትስ የትኛው ነው? አማራውና መከላከያው ውጊያ ሜዳ ላይ ሲውል ይህ ሚድያ የትኛው ነው? አማራውና መከላከያው ውጊያ ሜዳ ላይ ሲውል ይህ ሚድያ የትኛው ነው? አማራውና መከላከያው ውጊያ ሜዳ ላይ ሲውል ይህ ሚድያ የትኛው ነው?",
         "False"
        ],
        [
         "174",
         "Я можу придумувати їбануті програми для СТБ.",
         "Я можу придумувати дивні програми для СТБ.",
         "Я можу придумувати програми для СТБ.",
         "False"
        ],
        [
         "181",
         "Schäuble zur Lage in der Türkei: \"Das erinnert mich daran, wie es in der DDR war\" Was weiß dieser Vollpfosten von der DDR 🤢",
         "Schäuble zur Lage in der Türkei: \"Das erinnert mich daran, wie es in der DDR war\" Was weiß dieser Mensch von der DDR 🤢",
         "Das erinnert mich daran, wie es in der DDR war\" Was weiß dieser Vollpfosten von der DDR 🤢",
         "False"
        ],
        [
         "187",
         "ተስፋ አደርጋለሁ ብዬ ተስፋ አደርጋለሁ ሰይጣን ወደ አንተ ይደርሳል ብዬ ተስፋ አደርጋለሁ በሲኦል ውስጥ እንደበሰብስኩ እና በህይወትዎ ውስጥ ያሉ መልካም ነገሮች ሁሉ ከእርስዎ እንደተ",
         "ተስፋ አደርጋለሁ ብዬ በሰረሁት መጥፎ ስራ እየተቀጠሁ እንደ ሆነ እና በህይወትዎ ውስጥ ያሉ መልካም ነገሮች",
         "ተስፋ አደርጋለሁ ብዬ ተስፋ አደርጋለሁ በሲኦል ውስጥ እንደበሰብስኩ እና በህይወትዎ ውስጥ ያሉ መልካም ነገሮች ሁሉ ከእርስዎ እንደተረዳሁ",
         "False"
        ],
        [
         "199",
         "አንድ ነገር ይገርመኛል ኑሮን ለማሸነፍ ነብሱን አሰይዞ በባህር አረብ ሀገር የገባውን ምሰኪን አሸባሪ ብሉ ሰቃዩንይሰቃይ ብሎ የፈረደበት የሀገር መሪ እንዴት ነው መሪ ይሆነኛል በየ",
         "አንድ ነገር ይገርመኛል ኑሮን ለማሸነፍ ነብሱን አሰይዞ በባህር አረብ ሀገር የገባውን ምሰኪን አታስፈልግም ብሎ የረሳውን መሪ እንዴት ነው መሪ ይሆነኛል በየ",
         "አንድ ነገር ይገርመኛል ኑሮን ለማሸነፍ ነብሱን አሰይዞ በባህር አረብ ሀገር የገባውን ምሰኪን አሸባሪ ብሎ የፈረደበት የሀገር መሪ እንዴት ነው መሪ ይሆነኛል በየ",
         "False"
        ],
        [
         "202",
         "Tusk wird in Polen als derjenige wahrgenommen, der Merkel in den Ar*** kriecht, war sich seiner \"Sache\" sicher u. verlor d. Wahl",
         "Tusk wird in Polen als derjenige wahrgenommen, der Merkel gefallen will, war sich seiner \"Sache\" sicher u. verlor d. Wahl",
         "Polen wird in Polen als derjenige wahrgenommen, der Merkel in den Ar*** kriecht, war sich seiner \"Sache\" sicher u. verlor d. Wahl",
         "False"
        ],
        [
         "204",
         "shit looked like a music video with synced audio , and footage editing .",
         "looked like a music video with synced audio , and footage editing .",
         "Something looked like a music video with synced audio , and footage editing .",
         "False"
        ],
        [
         "207",
         "'П''яний друг каже: \" ніколи не трахай дівчат з економічного...\"'",
         "'П''яний друг каже: \" ніколи займайся сексом с дівчатами з економічного...\"'",
         "'П''яний друг каже: \"ніколи не трахай дівчат з економічного...\"'",
         "False"
        ],
        [
         "217",
         "አንቺ የውሻ ልጅ የሚሰረቅ ያለው በኢትዮጽያ ስም የተመዘገበ የሕዝብ ንብረት ነው። መሀይም",
         "አንቺ የሚሰረቅ ያለው በኢትዮጽያ ስም የተመዘገበ የሕዝብ ንብረት ነው -አልገባሽም እንዴ",
         "አንቺ የውሻ ልጅ የሚሰረቅ ያለው በኢትዮጽያ ስም የተመዘገበ የሕዝብ ንብረት ነው።",
         "False"
        ],
        [
         "220",
         "लगता है मेरठ के लोग भड़वा बन गए है",
         "लगता है मेरठ के लोग बेकार बन गए हैं",
         "मेरठ के लोग भड़वा बन गए है",
         "False"
        ],
        [
         "224",
         "ባለጌው አንተ ክፉ ልክስክስ። ተመልሰህ ወጥተህ ይቅርታ ጠይቅ። ስሜታዊ ሆኜ ነው በል። እንደ አንተ ርካሽ ደግሞ አላየሁም። ሰላም በጔደ",
         "አንተ ስርአት የሌለህ ተመልሰህ ወጥተህ ይቅርታ ጠይቅ። ስሜታዊ ሆኜ ነው በል።",
         "የባለጌው አንተ ክፉ ልክስክስ። ተመልሰህ ወጥተህ ይቅርታ ጠይቅ። ስሜታዊ ሆኜ ነው በል። እንደ አንተ ርካሽ ደግሞ አላየሁም። ሰላም በጔደ",
         "False"
        ],
        [
         "226",
         "አንቺ ደደብ ስለ ሃገርሽ የምታስቢ ከሆነ ወሬሽን ከምትነፊ አንድ የዳቦ ለተራበው የትግራይ ምስኪኑ ህዝብ ብትረጅው ይሻላል",
         "ስለ ሃገርሽ የምታስቢ ከሆነ ሌላ ነገር ትተሽ አንድ የዳቦ ለተራበው የትግራይ ምስኪኑ ህዝብ ብትረጅው ይሻላል",
         "አንቺ ስለ ሃገርሽ የምታስቢ ከሆነ ወሬሽን ከምትነፊ አንድ የዳቦ ለተራበው የትግራይ ምስኪኑ ህዝብ ብትረጅው ይሻላል",
         "False"
        ],
        [
         "233",
         "货拉拉司机无罪判一年,小仙女鲨人未遂判四个月",
         "货拉拉司机无罪判一年,这位行为极端的女性鲨人未遂判四个月",
         "货拉拉司机无罪判一年,小仙女未遂判四个月",
         "False"
        ],
        [
         "236",
         "как всегда сказочно напиздел, особенно про дочку вкатившую себе вакцину. мудак...",
         "Как всегда сказочно рассказал, особенно про дочку, сделавшую себе вакцину",
         "як всегда сказочно напиздел, особенно про дочку вкатившую себе вакцину.",
         "False"
        ],
        [
         "237",
         "यह है मादरचोद कॉंग्रेस की राजनीति इन मादर चोदो कांग्रेसियों ने इतना गंद फैलाया है",
         "यह है कॉंग्रेस की राजनीति इन कांग्रेसियों ने इतना रायता फैलाया है",
         "यह है कॉंग्रेस की राजनीति इन मादर चोदो कांग्रेसियों ने इतना गंद फैलाया है",
         "False"
        ],
        [
         "246",
         "Ну бляяя, чого вони такі каєфні?",
         "Ну чого вони такі каєфні?",
         "Ну бляяя, чого вони такі?",
         "False"
        ],
        [
         "249",
         "阿三不比黑哥干净多了???",
         "印度人不比黑人更注重个人卫生吗???",
         "黑哥不比黑哥干净多了???",
         "False"
        ],
        [
         "252",
         "хорош хуеть !!!!я сейчас еще в службу поддержки нахурярю на вас защеканцы!!!!!!!!!!",
         "Не наглейте!!! Я сейчас еще в службу поддержки напишу на вас не хорошие люди",
         "я сейчас еще в службу поддержки нахурярю на вас защеканцы!!!!!!!!!!",
         "False"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 72
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>gold_neutral</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>equals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>мразь тебя нужно вывести за грань , захрибетни...</td>\n",
       "      <td>тебя нужно вывести за грань , ешь с рук этих у...</td>\n",
       "      <td>Человек тебя нужно вывести за грань , захрибет...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>piss me off , fuckin jerk , get on my nerves .</td>\n",
       "      <td>get on my nerves</td>\n",
       "      <td>Pis me off , fuckin jerk , get on my nerves .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>вже майже четверта, а я не сплю, блять</td>\n",
       "      <td>вже майже четверта, а я не сплю, що за</td>\n",
       "      <td>Вже майже четверта, а я не сплю</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>वाह भेनचोद वाह ...एक आदमी को नीचे गिराने के लि...</td>\n",
       "      <td>वाह भाई वाह ... एक आदमी को नीचा गिराने के लिए ...</td>\n",
       "      <td>वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>кошмар, руки бы оторвать. придурки .:o</td>\n",
       "      <td>ужасно!</td>\n",
       "      <td>Комар, руки бы оторвать. придурки .:o</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>boeing is behaving exactly like any greedy bul...</td>\n",
       "      <td>Boeing is behaving unfairly</td>\n",
       "      <td>bully is behaving exactly like any bully would .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Має дві роботи, але вкрай ниє, яка у нас хрено...</td>\n",
       "      <td>Має дві роботи, але вкрай ниє, яка у нас хрено...</td>\n",
       "      <td>Має дві роботи, але вкрай ниє, яка у нас хрено...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Der dumme Deutsche hat gewählt er läuft freiwi...</td>\n",
       "      <td>Der Deutsche hat gewählt er läuft freiwillig z...</td>\n",
       "      <td>Der dumme Deutsche hat gewählt er läuft freiwi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>this is a fuckingtzu tactic for shits sake .</td>\n",
       "      <td>that's a bad tactic</td>\n",
       "      <td>This is a tactic for shits sake .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>веселись сегодня ептить удручённый ты наш:-d</td>\n",
       "      <td>Веселись сегодня, удрученный ты наш)))</td>\n",
       "      <td>сегодня веселись сегодня ептить удручённый ты ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 toxic  \\\n",
       "14   мразь тебя нужно вывести за грань , захрибетни...   \n",
       "16      piss me off , fuckin jerk , get on my nerves .   \n",
       "25              вже майже четверта, а я не сплю, блять   \n",
       "33   वाह भेनचोद वाह ...एक आदमी को नीचे गिराने के लि...   \n",
       "35              кошмар, руки бы оторвать. придурки .:o   \n",
       "..                                                 ...   \n",
       "333  boeing is behaving exactly like any greedy bul...   \n",
       "334  Має дві роботи, але вкрай ниє, яка у нас хрено...   \n",
       "335  Der dumme Deutsche hat gewählt er läuft freiwi...   \n",
       "352       this is a fuckingtzu tactic for shits sake .   \n",
       "357       веселись сегодня ептить удручённый ты наш:-d   \n",
       "\n",
       "                                          gold_neutral  \\\n",
       "14   тебя нужно вывести за грань , ешь с рук этих у...   \n",
       "16                                    get on my nerves   \n",
       "25              вже майже четверта, а я не сплю, що за   \n",
       "33   वाह भाई वाह ... एक आदमी को नीचा गिराने के लिए ...   \n",
       "35                                             ужасно!   \n",
       "..                                                 ...   \n",
       "333                        Boeing is behaving unfairly   \n",
       "334  Має дві роботи, але вкрай ниє, яка у нас хрено...   \n",
       "335  Der Deutsche hat gewählt er läuft freiwillig z...   \n",
       "352                                that's a bad tactic   \n",
       "357             Веселись сегодня, удрученный ты наш)))   \n",
       "\n",
       "                                     predicted_neutral  equals  \n",
       "14   Человек тебя нужно вывести за грань , захрибет...   False  \n",
       "16       Pis me off , fuckin jerk , get on my nerves .   False  \n",
       "25                     Вже майже четверта, а я не сплю   False  \n",
       "33   वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग...   False  \n",
       "35               Комар, руки бы оторвать. придурки .:o   False  \n",
       "..                                                 ...     ...  \n",
       "333   bully is behaving exactly like any bully would .   False  \n",
       "334  Має дві роботи, але вкрай ниє, яка у нас хрено...   False  \n",
       "335  Der dumme Deutsche hat gewählt er läuft freiwi...   False  \n",
       "352                  This is a tactic for shits sake .   False  \n",
       "357  сегодня веселись сегодня ептить удручённый ты ...   False  \n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_modified[results_modified['equals'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6df150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "toxic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gold_neutral",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_neutral",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "equals",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "overlap_toxic",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "overlap_neutral",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missing_words_toxic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "missing_words_neutral",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7b5945ae-a411-485a-9786-85ceac3ec396",
       "rows": [
        [
         "0",
         "wir brauchen das scheiß #Europa nicht ich bin #Deutscher und kein Europäer #btw2017",
         "wir brauchen das #Europa nicht ich bin #Deutscher und kein Europäer #btw2017",
         "Wir brauchen das scheiß #Europa nicht ich bin #Deutscher und kein Europäer #btw2017",
         "False",
         "0.9230769230769231",
         "0.9230769230769231",
         "1",
         "1"
        ],
        [
         "4",
         "ты сама то что сделала? ни хера ты не сделала",
         "Ты сама то что сделала? Ничего ты не сделала",
         "Ты сама то что сделала? ни хера ты не сделала",
         "False",
         "0.9",
         "0.9",
         "0",
         "1"
        ],
        [
         "14",
         "мразь тебя нужно вывести за грань , захрибетник- жреш с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "тебя нужно вывести за грань , ешь с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "Человек тебя нужно вывести за грань , захрибетник- жреш с рук этих учителей и рабочего класса и их -же угнетаешь.",
         "False",
         "0.9473684210526315",
         "0.9473684210526315",
         "1",
         "1"
        ],
        [
         "16",
         "piss me off , fuckin jerk , get on my nerves .",
         "get on my nerves",
         "Pis me off , fuckin jerk , get on my nerves .",
         "False",
         "0.9090909090909091",
         "0.9090909090909091",
         "1",
         "1"
        ],
        [
         "25",
         "вже майже четверта, а я не сплю, блять",
         "вже майже четверта, а я не сплю, що за",
         "Вже майже четверта, а я не сплю",
         "False",
         "0.625",
         "0.625",
         "3",
         "2"
        ],
        [
         "33",
         "वाह भेनचोद वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग लगे हुए हैं ...",
         "वाह भाई वाह ... एक आदमी को नीचा गिराने के लिए कितने लोग हैं",
         "वाह ...एक आदमी को नीचे गिराने के लिए कितने लोग लगे हुए हैं ...",
         "False",
         "0.9333333333333333",
         "0.9333333333333333",
         "1",
         "0"
        ],
        [
         "35",
         "кошмар, руки бы оторвать. придурки .:o",
         "ужасно!",
         "Комар, руки бы оторвать. придурки .:o",
         "False",
         "0.8333333333333334",
         "0.8333333333333334",
         "1",
         "1"
        ],
        [
         "38",
         "collins , is an idiot , but we didnt need this article to establish that fact .",
         "Colin is not so intelligent but we didn't need this article to establish this fact.",
         ", is an idiot , but we didnt need this article to establish that fact .",
         "False",
         "0.9375",
         "0.9375",
         "1",
         "0"
        ],
        [
         "42",
         "и наверное написав эдакую херню, ещё и гордый ходит , как бамбук.",
         "И наверное написав такую ерунду, ещё и гордый ходит",
         "И наверное написав эдакую херню, ещё и гордый ходит , как бамбук.",
         "False",
         "0.9166666666666666",
         "0.9166666666666666",
         "0",
         "1"
        ],
        [
         "46",
         "не хуй руку поднимать на благородное создание, а сам он животное.",
         "Не надо руку поднимать на благородное создание, а сам он нехороший человек",
         "Не хуй руку поднимать на благородное создание, а сам он животное.",
         "False",
         "0.9090909090909091",
         "0.9090909090909091",
         "1",
         "1"
        ],
        [
         "49",
         "твоё очко уходит в пользу форума!",
         "ваш балл уходит в пользу форума!",
         "Ты уходит в пользу форума!",
         "False",
         "0.6666666666666666",
         "0.6666666666666666",
         "2",
         "1"
        ],
        [
         "53",
         "this is some clockwork orange level shit .",
         "this is some clockwork orange level thing",
         "This is some clockwork orange level shit .",
         "False",
         "0.875",
         "0.875",
         "1",
         "1"
        ],
        [
         "58",
         "you know more than these idiots , stay the course and the truth will prevail .",
         "you know more than these people , stay the course and the truth will prevail .",
         "You know more than these idiots , stay the course and the truth will prevail .",
         "False",
         "0.9333333333333333",
         "0.9333333333333333",
         "1",
         "1"
        ],
        [
         "60",
         "дак и нечего с своим свиным рылом лезть ко всем .....",
         "дак и нечего лезть ко всем .....",
         "дак и нечего с своим рылом лезть ко всем .....",
         "False",
         "0.9090909090909091",
         "0.9090909090909091",
         "1",
         "0"
        ],
        [
         "62",
         "Jakarta nur Drecks Islamisten !!! sie wollen Christen verfolgen ....!!!",
         "Jakarta nur Islamisten !!! sie wollen Christen verfolgen ....!!!",
         "jakarta nur Drecks Islamisten !!! sie wollen Christen verfolgen ....!!!",
         "False",
         "0.9",
         "0.9",
         "1",
         "1"
        ],
        [
         "63",
         "Ja schnell alle Bäume weg, 5G Handys kaufen und Bürgermeister den Sack lutschen du kleine Profesora",
         "Ja schnell alle Bäume weg, 5G Handys kaufen und Bürgermeister schmeicheln Profesora",
         "Ja schnell alle Bäume weg, 5G Handys kaufen und Bürgermeister den Sack lutschen",
         "False",
         "0.8125",
         "0.8125",
         "3",
         "0"
        ],
        [
         "65",
         "везде бабушки блядь а дедушки ведь она пиздует к внукам а дед ебашет на работе и всегда она хорошая а дед хуевый парадокс",
         "везде бабушки и дедушки: бабушка ездит к внукам, а дед работает, но она всегда хорошая, а дедушка плохой. Парадокс!",
         "Везде бабушки блядь а дедушки ведь она пиздует к внукам а дед ебашет на работе и всегда она хорошая",
         "False",
         "0.8421052631578947",
         "0.8421052631578947",
         "3",
         "1"
        ],
        [
         "66",
         "Тому доводиться вмикати режим хитрожопість.",
         "Тому доводиться вмикати режим хитрощів.",
         "Тому доводиться вмикати режим хитрожопості.",
         "False",
         "0.8",
         "0.8",
         "1",
         "1"
        ],
        [
         "67",
         "这就是慕勾正常人谁和蝻结婚啊",
         "这就是让我反感的女性正常人谁和国内男性结婚啊",
         "这就是慕勾正常人谁和黑人结婚啊",
         "False",
         "0.0",
         "0.0",
         "1",
         "1"
        ],
        [
         "68",
         "явная цензура, 100% заказ пидаров с газпрома, ебучая контора",
         "явная цензура, 100% заказ людей с газпрома, плохая контора",
         "Яная цензура, 100% заказ пидаров с газпрома, ебучая контора",
         "False",
         "0.8888888888888888",
         "0.8888888888888888",
         "1",
         "1"
        ],
        [
         "69",
         "тобто блядь? тобі більше 25?!",
         "тобто? тобі більше 25?!",
         "Точно блядь? тобі більше 25?!",
         "False",
         "0.8",
         "0.8",
         "1",
         "1"
        ],
        [
         "72",
         "Son los mejores. Paguita, alquiler y seguridad social ya. Rasistas",
         "Son los mejores. Paguita, alquiler y seguridad social ya.",
         "Los mejores. Paguita, alquiler y seguridad social ya.",
         "False",
         "0.7",
         "0.7",
         "3",
         "1"
        ],
        [
         "74",
         "курва галичанская , приехала в одессу со своим уставом !",
         "глупышка, приехала в одессу со своим уставом !",
         ", приехала в одессу со своим уставом !",
         "False",
         "0.8",
         "0.8",
         "2",
         "0"
        ],
        [
         "75",
         "عنجد هيدا شارون هيدا جماعة شارون لعنة الله عليك يا مجرم يا ابن الحرام لعنة الله يارب تخسر أولادك",
         "عنجد هيدا شارون هيدا جماعة شارون يارب تخسر أولادك",
         "عنجد هيدا شارون لعنة الله عليك يا مجرم يا ابن الحرام لعنة الله يارب تخسر أولادك",
         "False",
         "0.9285714285714286",
         "0.9285714285714286",
         "1",
         "0"
        ],
        [
         "76",
         "you need to fuck off and stop hrassing people",
         "You need to stop hrassing people",
         "You need to fuck off and stop hrassing people",
         "False",
         "0.8888888888888888",
         "0.8888888888888888",
         "1",
         "1"
        ],
        [
         "77",
         "а свое мнение и мысли при себе держи мудило ебаное.",
         "оставьте свои мысли при себе",
         "а свое мнение и мысли при себе держи ебаное.",
         "False",
         "0.9",
         "0.9",
         "1",
         "0"
        ],
        [
         "87",
         "op沙軟罢了",
         "op不明智罢了",
         "Op沙软罢了",
         "False",
         "0.0",
         "0.0",
         "1",
         "1"
        ],
        [
         "89",
         "Merkel: \"Die Bürger haben keine Lust auf Zuständigkeitsdebatten\" ??? Eben ein verlogenes Miststück mit ausreichender Denunziantenerfahrung😜",
         "Merkel: \"Die Bürger haben keine Lust auf Zuständigkeitsdebatten\" ??? Eben eine Politikerin mit ausreichender rethorischer Erfahrung 😜",
         "Angela: \"Die Bürger haben keine Lust auf Zuständigkeitsdebatten\" ??? Eben ein verlogenes Miststück mit ausreichender Denunziantenerfahrung😜",
         "False",
         "0.9375",
         "0.9375",
         "1",
         "1"
        ],
        [
         "90",
         "вас три дуры в этом обсуждении верят в ковид!",
         "вас три женщины в этом обсуждении верят в ковид!",
         "Вас три дуры в этом обсуждении верят в ковид!",
         "False",
         "0.875",
         "0.875",
         "1",
         "1"
        ],
        [
         "91",
         "وأمور أخرى غبية .",
         "وأمور أخرى سيئة .",
         "أمور أخرى غبية .",
         "False",
         "0.75",
         "0.75",
         "1",
         "1"
        ],
        [
         "98",
         "Dummes Gelaber wegen Abschiebung in unsichere Staaten. Berlin, Manchester. und Nizza liegen auch in unsicheren Staaten. Also keine Hemmungen.",
         "Unnötiges Gespräch wegen Abschiebung in unsichere Staaten. Berlin, Manchester. und Nizza liegen auch in unsicheren Staaten. Also keine Hemmungen.",
         "wegen Abschiebung in unsichere Staaten. Berlin, Manchester. und Nizza liegen auch in unsicheren Staaten. Also keine Hemmungen.",
         "False",
         "0.8823529411764706",
         "0.8823529411764706",
         "2",
         "0"
        ],
        [
         "104",
         "सूअर लोग अपना अस्तित्व बचाने में लगे हैं।।",
         "बुरे लोग अपने अस्तित्व को बचाने में लगे हैं |",
         "अपना अस्तित्व बचाने में लगे हैं।।",
         "False",
         "0.75",
         "0.75",
         "2",
         "0"
        ],
        [
         "112",
         "Aquí va una canción para todos y cada uno de los putos fascistas del PP... Fuck You de Lily Allen",
         "Aquí tenéis una canción para todos y cada uno de los PP... You de Lily Allen",
         "Aquí va una canción para todos y cada uno de los fascistas del PP... Fuck You de Lily Allen",
         "False",
         "0.9473684210526315",
         "0.9473684210526315",
         "1",
         "0"
        ],
        [
         "113",
         "if you think a town in texas would cover this kind of shit up you re insane .",
         "If you think a town in Texas would cover these things your wrong.",
         "If you think a town in texas would cover this kind of shit up you re insane",
         "False",
         "0.8823529411764706",
         "0.8823529411764706",
         "2",
         "1"
        ],
        [
         "125",
         "Puto perroflautas que man rayao el mercedes",
         "que man rayao el mercedes",
         "Puto perroflautas que man rayao el Mercedes",
         "False",
         "0.8571428571428571",
         "0.8571428571428571",
         "1",
         "1"
        ],
        [
         "128",
         "but redditors are too busy sucking bernie s dick to care .",
         "but redditors are too busy to care .",
         "But redditors are too busy sucking bernie s dick to care .",
         "False",
         "0.9166666666666666",
         "0.9166666666666666",
         "1",
         "1"
        ],
        [
         "131",
         "por desgracia aún no entregan Goyas por el simple hecho de ser subnormal. Deberían empezar",
         "por desgracia aún no entregan Goyas",
         "Por desgracia aún no entregan Goyas por el simple hecho de ser subnormal. Deberían empezar",
         "False",
         "0.9333333333333333",
         "0.9333333333333333",
         "0",
         "1"
        ],
        [
         "132",
         "так этот акимат только себе в карман ложит бабки а для людей они нечего делать не будут хуилы ни дорог ни парка полная жопа гавноеды",
         "так этот акимат только себе в карман кладет деньги. а для людей они нечего делать не будут. ни дорог, ни парка. полное разочарование",
         "так этот акимат только себе в карман ложит бабки а для людей они нечего делать не будут",
         "False",
         "0.7083333333333334",
         "0.7083333333333334",
         "7",
         "0"
        ],
        [
         "134",
         "с которым через час расстанешься и будешь трахаться с другими?",
         "С которым через час расстанешься и встретишь другого?",
         "С которым через час расстанешься и будешь трахаться с другими?",
         "False",
         "0.9",
         "0.9",
         "0",
         "1"
        ],
        [
         "139",
         "que asco de gente dios, que busquen el significado de hembrismo y de feminismo y luego hablan",
         "Que terrible gente dios, que busquen el significado de hembrismo y de feminismo y luego hablan",
         "Que asco de gente dios, que busquen el significado de hembrismo y de feminismo y luego hablan",
         "False",
         "0.9285714285714286",
         "0.9285714285714286",
         "0",
         "1"
        ],
        [
         "142",
         "не плєд хуйня, а ти хуйня",
         "Не плед фігня,а ти",
         "Не плєд хуйня, а ти хуйня",
         "False",
         "0.8333333333333334",
         "0.8333333333333334",
         "1",
         "1"
        ],
        [
         "143",
         "it s like fucking jurassic park , but much fluffier ! .",
         "it s like jurassic park , but much fluffier !",
         "It s like fucking jurassic park , but much fluffier !",
         "False",
         "0.8333333333333334",
         "0.8333333333333334",
         "2",
         "1"
        ],
        [
         "148",
         "सालो को जेल में डाल तो क्या रे बिकाऊ दलाल पत्रकार",
         "ऐसे बिकाऊ चापलूस पत्रकार को जेल में डाल दो",
         "सालो को जेल में डाल तो क्या रे बिकाऊ पत्रकार",
         "False",
         "0.9090909090909091",
         "0.9090909090909091",
         "1",
         "0"
        ],
        [
         "149",
         "केला कहाँ मिल रहा है आज कल सुअर ?",
         "केला कहाँ मिल रहा है आज कल ?",
         "कहाँ मिल रहा है आज कल सुअर ?",
         "False",
         "0.8888888888888888",
         "0.8888888888888888",
         "1",
         "0"
        ],
        [
         "150",
         "я за сьогодні вже 2 рази блять, руки реально з жопи ростуть",
         "я за сьогодні вже 2 рази , руки реально нiзвiдки треба ростуть",
         "Я за сьогодні вже 2 рази блять, руки реально з жопи ростуть",
         "False",
         "0.9166666666666666",
         "0.9166666666666666",
         "1",
         "1"
        ],
        [
         "151",
         "so shut the hell up until you know what it is your talking about .",
         "So keep quiet untill you know what you are talking about.",
         "So shut the hell up until you know what it is your talking about",
         "False",
         "0.8666666666666667",
         "0.8666666666666667",
         "2",
         "1"
        ],
        [
         "154",
         "für derart strunzdumme Menschen die ihre Gesundheit bei Wetten Dass ruinieren sollte die Öffentlichkeit keinesfalls aufkommen #hartaberfair",
         "für Menschen die ihre Gesundheit bei Wetten Dass ruinieren sollte die Öffentlichkeit keinesfalls aufkommen #hartaberfair",
         "Für derart strunzdumme Menschen die ihre Gesundheit bei Wetten Dass ruinieren sollte die Öffentlichkeit keinesfalls aufkommen #hartaberfair",
         "False",
         "0.9375",
         "0.9375",
         "1",
         "1"
        ],
        [
         "155",
         "that s fucking murder in my book and they let parents off for that shit all of the time .",
         "that is murder in my book and they let parents off for that all the time .",
         "That s fucking murder in my book and they let parents off for that shit all of the time .",
         "False",
         "0.95",
         "0.95",
         "0",
         "1"
        ],
        [
         "165",
         "La mitad catalana borrega independentista sigue creyéndose sus mentiras.",
         "La mitad catalana independentista sigue creyéndose sus mentiras",
         "La mitad catalana sigue creyéndose sus mentiras.",
         "False",
         "0.7777777777777778",
         "0.7777777777777778",
         "2",
         "0"
        ],
        [
         "167",
         "舔狗龜男比拳師更可恨",
         "单方面付出的卑微男性比极端的性别平等倡导者更可恨",
         "舔狗男比拳師更可恨",
         "False",
         "0.0",
         "0.0",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 102
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>gold_neutral</th>\n",
       "      <th>predicted_neutral</th>\n",
       "      <th>equals</th>\n",
       "      <th>overlap_toxic</th>\n",
       "      <th>overlap_neutral</th>\n",
       "      <th>missing_words_toxic</th>\n",
       "      <th>missing_words_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wir brauchen das scheiß #Europa nicht ich bin ...</td>\n",
       "      <td>wir brauchen das #Europa nicht ich bin #Deutsc...</td>\n",
       "      <td>Wir brauchen das scheiß #Europa nicht ich bin ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ты сама то что сделала? ни хера ты не сделала</td>\n",
       "      <td>Ты сама то что сделала? Ничего ты не сделала</td>\n",
       "      <td>Ты сама то что сделала? ни хера ты не сделала</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>мразь тебя нужно вывести за грань , захрибетни...</td>\n",
       "      <td>тебя нужно вывести за грань , ешь с рук этих у...</td>\n",
       "      <td>Человек тебя нужно вывести за грань , захрибет...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>piss me off , fuckin jerk , get on my nerves .</td>\n",
       "      <td>get on my nerves</td>\n",
       "      <td>Pis me off , fuckin jerk , get on my nerves .</td>\n",
       "      <td>False</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>вже майже четверта, а я не сплю, блять</td>\n",
       "      <td>вже майже четверта, а я не сплю, що за</td>\n",
       "      <td>Вже майже четверта, а я не сплю</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Der dumme Deutsche hat gewählt er läuft freiwi...</td>\n",
       "      <td>Der Deutsche hat gewählt er läuft freiwillig z...</td>\n",
       "      <td>Der dumme Deutsche hat gewählt er läuft freiwi...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>ты что дура ,кто кормил ? путин что-ли?даже за...</td>\n",
       "      <td>Кто кормил? Путин что-ли? Налог даже с грудног...</td>\n",
       "      <td>Ты что дура ,кто кормил ? путин что-ли?даже за...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>люди убедительная просьба не обращать на эту д...</td>\n",
       "      <td>люди убедительная просьба не обращать на эту ж...</td>\n",
       "      <td>Люди убедительная просьба не обращать на эту д...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>this is a fuckingtzu tactic for shits sake .</td>\n",
       "      <td>that's a bad tactic</td>\n",
       "      <td>This is a tactic for shits sake .</td>\n",
       "      <td>False</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>веселись сегодня ептить удручённый ты наш:-d</td>\n",
       "      <td>Веселись сегодня, удрученный ты наш)))</td>\n",
       "      <td>сегодня веселись сегодня ептить удручённый ты ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 toxic  \\\n",
       "0    wir brauchen das scheiß #Europa nicht ich bin ...   \n",
       "4        ты сама то что сделала? ни хера ты не сделала   \n",
       "14   мразь тебя нужно вывести за грань , захрибетни...   \n",
       "16      piss me off , fuckin jerk , get on my nerves .   \n",
       "25              вже майже четверта, а я не сплю, блять   \n",
       "..                                                 ...   \n",
       "335  Der dumme Deutsche hat gewählt er läuft freiwi...   \n",
       "345  ты что дура ,кто кормил ? путин что-ли?даже за...   \n",
       "350  люди убедительная просьба не обращать на эту д...   \n",
       "352       this is a fuckingtzu tactic for shits sake .   \n",
       "357       веселись сегодня ептить удручённый ты наш:-d   \n",
       "\n",
       "                                          gold_neutral  \\\n",
       "0    wir brauchen das #Europa nicht ich bin #Deutsc...   \n",
       "4         Ты сама то что сделала? Ничего ты не сделала   \n",
       "14   тебя нужно вывести за грань , ешь с рук этих у...   \n",
       "16                                    get on my nerves   \n",
       "25              вже майже четверта, а я не сплю, що за   \n",
       "..                                                 ...   \n",
       "335  Der Deutsche hat gewählt er läuft freiwillig z...   \n",
       "345  Кто кормил? Путин что-ли? Налог даже с грудног...   \n",
       "350  люди убедительная просьба не обращать на эту ж...   \n",
       "352                                that's a bad tactic   \n",
       "357             Веселись сегодня, удрученный ты наш)))   \n",
       "\n",
       "                                     predicted_neutral  equals  overlap_toxic  \\\n",
       "0    Wir brauchen das scheiß #Europa nicht ich bin ...   False       0.923077   \n",
       "4        Ты сама то что сделала? ни хера ты не сделала   False       0.900000   \n",
       "14   Человек тебя нужно вывести за грань , захрибет...   False       0.947368   \n",
       "16       Pis me off , fuckin jerk , get on my nerves .   False       0.909091   \n",
       "25                     Вже майже четверта, а я не сплю   False       0.625000   \n",
       "..                                                 ...     ...            ...   \n",
       "335  Der dumme Deutsche hat gewählt er läuft freiwi...   False       0.923077   \n",
       "345  Ты что дура ,кто кормил ? путин что-ли?даже за...   False       0.944444   \n",
       "350  Люди убедительная просьба не обращать на эту д...   False       0.888889   \n",
       "352                  This is a tactic for shits sake .   False       0.777778   \n",
       "357  сегодня веселись сегодня ептить удручённый ты ...   False       1.000000   \n",
       "\n",
       "     overlap_neutral  missing_words_toxic  missing_words_neutral  \n",
       "0           0.923077                    1                      1  \n",
       "4           0.900000                    0                      1  \n",
       "14          0.947368                    1                      1  \n",
       "16          0.909091                    1                      1  \n",
       "25          0.625000                    3                      2  \n",
       "..               ...                  ...                    ...  \n",
       "335         0.923077                    1                      0  \n",
       "345         0.944444                    1                      1  \n",
       "350         0.888889                    1                      1  \n",
       "352         0.777778                    2                      1  \n",
       "357         1.000000                    0                      0  \n",
       "\n",
       "[102 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the overlap between toxic and predicted_neutral for the rows where they are not equal\n",
    "results_modified['overlap_toxic'] = results_modified.apply(lambda row: len(set(row['toxic'].split()).intersection(set(row['predicted_neutral'].split()))) / max(len(set(row['toxic'].split())), len(set(row['predicted_neutral'].split()))), axis=1)\n",
    "results_modified['overlap_neutral'] = results_modified.apply(lambda row: len(set(row['toxic'].split()).intersection(set(row['predicted_neutral'].split()))) / max(len(set(row['toxic'].split())), len(set(row['predicted_neutral'].split()))), axis=1)\n",
    "\n",
    "results_modified['missing_words_toxic'] = results_modified.apply(lambda row: len(set(row['toxic'].split()) - set(row['predicted_neutral'].split())), axis=1)\n",
    "results_modified['missing_words_neutral'] = results_modified.apply(lambda row: len(set(row['predicted_neutral'].split()) - set(row['toxic'].split())), axis=1)\n",
    "\n",
    "results_modified[results_modified['equals'] == False]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
